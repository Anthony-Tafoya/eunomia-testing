{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "import sparse\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import Utils.dbutils as dbutils\n",
    "import Utils.data_utils as data_utils\n",
    "# import Utils.PopulateAux as PopulateAux\n",
    "import Generators.CohortGenerator as CohortGenerator\n",
    "import Generators.FeatureGenerator as FeatureGenerator\n",
    "import config\n",
    "local_imports = (\n",
    "    dbutils,\n",
    "    data_utils,\n",
    "    # PopulateAux,\n",
    "    CohortGenerator,\n",
    "    FeatureGenerator,\n",
    "    config\n",
    ")\n",
    "for i in local_imports:\n",
    "    i = importlib.reload(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort, Outcome and Feature Collection\n",
    "\n",
    "### 1. Set up a connection to the OMOP CDM database\n",
    "\n",
    "Parameters for connection to be specified in ./config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database connection\n",
    "username = config.PG_USERNAME\n",
    "password = config.PG_PASSWORD\n",
    "database_name = config.DB_NAME\n",
    "\n",
    "config_path = 'postgresql://{username}:{password}@{database_name}'.format(\n",
    "    username = username,\n",
    "    password = password,\n",
    "    database_name = database_name\n",
    ")\n",
    "\n",
    "# schemas \n",
    "schema_name = 'flexible_windows_fixed_test' # all created tables will be created using this schema\n",
    "\n",
    "# caching\n",
    "reset_schema = False # if true, rebuild all data from scratch\n",
    "\n",
    "# set up database, reset schemas as needed\n",
    "db = dbutils.Database(config_path, schema_name)\n",
    "if reset_schema:\n",
    "    db.execute(\n",
    "        'drop schema if exists {} cascade'.format(schema_name)\n",
    "    )\n",
    "db.execute(\n",
    "    'create schema if not exists {}'.format(schema_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Cohort for the End of Life Prediction Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a Cohort Object that can be constructed as specified by SQL File & Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_name = 'test_cohort_all_prediction_times_heldout'\n",
    "cohort_script_path = config.SQL_PATH_COHORTS + '/test_cohort_all_prediction_times_heldout.sql'\n",
    "\n",
    "# cohort parameters  \n",
    "params = {\n",
    "          'cohort_table_name'     : cohort_name,\n",
    "          'schema_name'           : schema_name,\n",
    "          'gap'                   : '3 months',\n",
    "          'outcome_window'        : '6 months',\n",
    "          'eligibility_period'    : '1 year',       ## Enrollment duration before prediction time\n",
    "          'positive_pred_unif'    : 'true',         ## If 'true', then uniformly sample deltas...\n",
    "          'positive_pred_delta'   : '6 months',     ## ...otherwise, fixed interval.\n",
    "          # 'negative_pred_date'    : '2017-01-01',  \n",
    "          'dummy_date'            : '1900-01-01',   ## Can be arbitrary, but must be consistent with feature SQL scripts\n",
    "          'max_prediction_date'   : '2017-01-01'    ## Only use prediction times up to this parameter   \n",
    "         }\n",
    "\n",
    "cohort = CohortGenerator.Cohort(\n",
    "    schema_name=schema_name,\n",
    "    cohort_table_name=cohort_name,\n",
    "    cohort_generation_script=cohort_script_path,\n",
    "    cohort_generation_kwargs=params,\n",
    "    outcome_col_name='y'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort.build(db, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort._cohort.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "plt.hist(pd.to_datetime(cohort._cohort[cohort._cohort.y == 1].end_date))\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator((1)))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b %Y\"))\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Prediction time for positive samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "plt.hist(pd.to_datetime(cohort._cohort[cohort._cohort.y == 0].end_date))\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator((1)))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b %Y\"))\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Prediction time for negative samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min end date for positive samples:\", min(cohort._cohort[cohort._cohort.y == 1].end_date))\n",
    "print(\"Max end date for positive samples:\", max(cohort._cohort[cohort._cohort.y == 1].end_date))\n",
    "print(\"Min end date for negative samples:\", min(cohort._cohort[cohort._cohort.y == 0].end_date))\n",
    "print(\"Max end date for negative samples:\", max(cohort._cohort[cohort._cohort.y == 0].end_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Time Series of Features for Cohort Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet = FeatureGenerator.FeatureSet(db)\n",
    "featureSet.add_default_features(\n",
    "    ['drugs_relative','conditions_relative','procedures_relative','specialty_relative'],\n",
    "    schema_name,\n",
    "    cohort_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Build the Feature Set by executing SQL queries and reading into sparse matrices\n",
    "cache_data_path = '/tmp/cache_data_flexible_fixed_test'\n",
    "featureSet.build(cohort, from_cached=False, cache_file=cache_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(featureSet.time_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "outcomes_filt, feature_matrix_3d_transpose, remap, good_feature_names = \\\n",
    "    FeatureGenerator.postprocess_feature_matrix(cohort, featureSet, training_end_date_col='dummy_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Model to Predict End of Life using this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Data to get a vector of counts over 1, 6, 12, 24 and infinity (represented by 10000 days) month windows for each Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "feature_matrix_counts, feature_names = data_utils.window_data(\n",
    "    window_lengths = [30, 180, 365, 730, 10000],\n",
    "    feature_matrix = feature_matrix_3d_transpose,\n",
    "    all_feature_names = good_feature_names,\n",
    "    cohort = cohort,\n",
    "    featureSet = featureSet,\n",
    "    cohort_end_date_col = 'dummy_date'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_counts.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_filt.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a standard sklearn modelling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    class_weight='balanced', C=0.02,\n",
    "    penalty='l1', fit_intercept=True,\n",
    "    solver='liblinear', random_state=0,\n",
    "    verbose=0, max_iter = 200, tol=1e-1\n",
    ")\n",
    "\n",
    "def sparse_ufunc(f):\n",
    "    def wrapper(*a, **k):\n",
    "        X = a[0]\n",
    "        if not scipy.sparse.isspmatrix(X):\n",
    "            raise ValueError\n",
    "        X2 = X.copy()\n",
    "        X2.data = f(X2.data, *(a[1:]), **k)\n",
    "        return X2\n",
    "    return wrapper\n",
    "\n",
    "@sparse_ufunc\n",
    "def tr_func(X, kwarg=1):\n",
    "    return np.clip(X, 0, kwarg)\n",
    "\n",
    "func = FunctionTransformer(\n",
    "    func=tr_func,\n",
    "    accept_sparse=True,\n",
    "    validate=True,\n",
    "    kw_args={'kwarg': 1}\n",
    ")\n",
    "\n",
    "# The classifier will transform each data point using func, which here takes a count vector to a binary vector\n",
    "# Then, it will use logistic regression to classify the transformed data\n",
    "clf = Pipeline([\n",
    "    ('func',func),\n",
    "    ('lr', lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate, Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(len(outcomes_filt))\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(\n",
    "    feature_matrix_counts.T, outcomes_filt, indices,\n",
    "    test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "VAL_SZ = 10000\n",
    "vals = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0]\n",
    "scores = []\n",
    "best_score = -1\n",
    "best_model = None\n",
    "for C in tqdm_notebook(vals):\n",
    "    lr = LogisticRegression(\n",
    "        class_weight='balanced', C=C,\n",
    "        penalty='l1', fit_intercept=True,\n",
    "        solver='liblinear', random_state=0,\n",
    "        verbose=0, max_iter = 200, tol=1e-1\n",
    "    )\n",
    "\n",
    "    clf = Pipeline([\n",
    "        ('func',func),\n",
    "        ('lr', lr)\n",
    "    ])\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = roc_auc_score(y_test[:VAL_SZ], clf.predict_proba(X_test[:VAL_SZ, :])[:, 1])\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = clf\n",
    "    scores.append(score)\n",
    "plt.plot(np.log(np.array(vals)), scores)\n",
    "plt.show();\n",
    "pred = best_model.predict_proba(X_test[VAL_SZ:, :])[:, 1]\n",
    "print('Model Test AUC: {0:.2f}'.format(roc_auc_score(y_test[VAL_SZ:], pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model : RoC and Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test[VAL_SZ:], pred)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.fill_between(fpr, tpr, color='b', alpha = 0.2,\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc_score(y_test[VAL_SZ:], pred))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic - EoL Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test[VAL_SZ:], pred)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test[VAL_SZ:], pred)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(\n",
    "    recall, precision, alpha=0.2, color='b',\n",
    "    label='P-R curve (average precision = %0.2f)' % average_precision\n",
    ")\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title('Precision-Recall curve - EoL Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARD test set\n",
    "From Rohan's notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "eol_data_path = '{INSERT PATH HERE}/eol_all_data.data'\n",
    "with open(, \"rb\" ) as f:\n",
    "    SAVED_MODEL_DATA = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_sard = SAVED_MODEL_DATA['cohort'] # cohort.cohort_ is a dataframe containing PID's and outcomes for each patient\n",
    "featureSet_sard = SAVED_MODEL_DATA['featureSet'] \n",
    "dataset_dict = SAVED_MODEL_DATA['dataset_dict'] \n",
    "feature_matrix_3d_transpose_sard = SAVED_MODEL_DATA['feature_matrix_3d_transpose'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect feature names\n",
    "good_feature_names_sard = np.vectorize(dataset_dict['maps']['concept'].get)(\n",
    "    dataset_dict['remap']['concept']\n",
    ")\n",
    "\n",
    "# get feature counts over the given time windows\n",
    "feature_matrix_counts_sard, feature_names_sard = data_utils.window_data_sorted(\n",
    "    window_lengths = [30, 180, 365, 730, 10000], # Fixed this because this set of windows does consistently better, but can choose other settings from list of options in paper\n",
    "    feature_matrix = feature_matrix_3d_transpose_sard,\n",
    "    all_feature_names = good_feature_names_sard,\n",
    "    cohort = cohort_sard, \n",
    "    featureSet = featureSet_sard\n",
    ")\n",
    "feature_matrix_counts_sard = feature_matrix_counts_sard.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack as vstack_spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, test and validate sets of patients\n",
    "val_size = 5000\n",
    "val_size_from_train = 14319 # VALIDATION SET MAY BE TOO SMALL, SO WE TAKE THE LAST `val_size_from_train` EXAMPLES OF TRAIN AND MOVE TO VAL\n",
    "indices_all_sard = range(len(dataset_dict['outcomes_filt']))\n",
    "X_train_sard, X_test_sard, y_train_sard, y_test_sard, indices_train_sard, indices_test_sard = train_test_split(\n",
    "    feature_matrix_counts_sard, dataset_dict['outcomes_filt'], indices_all_sard,\n",
    "    test_size=0.2, random_state=1\n",
    ")\n",
    "X_val_sard = X_train_sard[-val_size_from_train:]\n",
    "y_val_sard = y_train_sard[-val_size_from_train:]\n",
    "\n",
    "X_val_sard = vstack_spm((X_val_sard, X_test_sard[:val_size]))\n",
    "y_val_sard = pd.concat((y_val_sard,  y_test_sard[:val_size]))\n",
    "\n",
    "X_train_sard = X_train_sard[:-val_size_from_train]\n",
    "y_train_sard = y_train_sard[:-val_size_from_train]\n",
    "\n",
    "X_test_sard = X_test_sard[val_size:]\n",
    "y_test_sard = y_test_sard[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SARD dataset dimension: %d, our dataset dimension: %d\" % (X_test_sard.shape[1], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Common features: %d\" % (len(set(feature_names).intersection(set(feature_names_sard)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reindex SARD test set to fit into this model\n",
    "feature_index_sard = {feature_names_sard[i]: i for i in range(len(feature_names_sard))}\n",
    "reindex = []\n",
    "for ft in feature_names:\n",
    "    if ft in feature_index_sard:\n",
    "        reindex.append(feature_index_sard[ft])\n",
    "    else:\n",
    "        reindex.append(len(feature_names_sard))  # will add zero column later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "X_test_sard_with_zero = csr_matrix(hstack([X_test_sard, csr_matrix(np.zeros((X_test_sard.shape[0], 1)))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sard_reindexed = X_test_sard_with_zero[:, reindex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC on SARD test set: {0:.2f}'.format(roc_auc_score(y_test_sard, best_model.predict_proba(X_test_sard_reindexed)[:, 1])))\n",
    "print('Average precision on SARD test set: %.2f' % (average_precision_score(y_test_sard, best_model.predict_proba(X_test_sard_reindexed)[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model : Extract Feature Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights = pd.DataFrame({\n",
    "    'feature_name': feature_names,\n",
    "    'feature_weight': list(best_model.get_params()['lr'].coef_[0])\n",
    "}).sort_values(by='feature_weight')\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for category in ['procedure', 'condition', 'drug', 'specialty']:\n",
    "    print('Number of nonzero {} feature weights : {}'.format(\n",
    "        category,\n",
    "        sum(feature_weights.loc[\n",
    "            [i for i,j in enumerate(feature_names) if '- ' + category + ' -' in j]\n",
    "        ]['feature_weight'] != 0)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
